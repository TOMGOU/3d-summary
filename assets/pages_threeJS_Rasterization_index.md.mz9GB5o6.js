import{_ as i,c as s,o as a,V as e}from"./chunks/framework.dnpgIXFM.js";const l="/3d-summary/assets/rasterize.vZEG_rex.png",t="/3d-summary/assets/sample1.yFXYjC6J.png",n="/3d-summary/assets/sample2.YvvRaC32.png",h="/3d-summary/assets/jaggies.6006U7G-.png",p="/3d-summary/assets/antialiasing.XUdTzT-Q.png",r="/3d-summary/assets/blurring.QqG1cZ7X.png",k="/3d-summary/assets/fourier.Y6A519WU.png",o="/3d-summary/assets/convolution.fOD9tN5u.png",d="/3d-summary/assets/triangles.NnfrJiNJ.png",g="/3d-summary/assets/zbuffercode.UZ-S4U_o.png",c="/3d-summary/assets/zbuffer.pknlV8fc.png",x=JSON.parse('{"title":"光栅化（Rasterization）","description":"","frontmatter":{},"headers":[],"relativePath":"pages/threeJS/Rasterization/index.md","filePath":"pages/threeJS/Rasterization/index.md"}'),u={name:"pages/threeJS/Rasterization/index.md"},E=e('<h1 id="光栅化-rasterization" tabindex="-1">光栅化（Rasterization） <a class="header-anchor" href="#光栅化-rasterization" aria-label="Permalink to &quot;光栅化（Rasterization）&quot;">​</a></h1><blockquote><p>在计算机图形学中，光栅化是将连续的几何形状和属性转换为离散像素的过程。在光栅化的过程中，取样是其中的核心概念之一。</p></blockquote><h2 id="取样-sampling" tabindex="-1">取样（Sampling） <a class="header-anchor" href="#取样-sampling" aria-label="Permalink to &quot;取样（Sampling）&quot;">​</a></h2><p><img src="'+l+`" alt="Rasterization"></p><div class="language-c++ vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">c++</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> xmax; </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">++</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">x)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">  for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> y </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; y </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> ymax; </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">++</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">y)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    image[x][y] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> inside</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(tri, x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, y </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0.5</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">);</span></span></code></pre></div><h3 id="inside-函数" tabindex="-1">inside 函数 <a class="header-anchor" href="#inside-函数" aria-label="Permalink to &quot;inside 函数&quot;">​</a></h3><p><img src="`+t+'" alt="Sampling"></p><p><img src="'+n+'" alt="Sampling"></p><p>向量叉乘右手螺旋定则：</p><ul><li> \\vec {AB} $$ · $$\\vec {AQ} $$ 方向为正，代表 Q 在 $$\\vec {AB} $$ 的左侧 </li><li> \\vec {CA} $$ · $$\\vec {CQ} $$ 方向为负，代表 Q 在 $$\\vec {CA} $$ 的右侧 </li></ul><h2 id="取样瑕疵-sampling-artifacts" tabindex="-1">取样瑕疵（Sampling Artifacts） <a class="header-anchor" href="#取样瑕疵-sampling-artifacts" aria-label="Permalink to &quot;取样瑕疵（Sampling Artifacts）&quot;">​</a></h2><ul><li><p>锯齿：Jaggies – sampling in space</p></li><li><p>摩尔纹：Moire – undersampling images</p></li><li><p>车轮效应：Wagon wheel effect – sampling in time</p></li></ul><h3 id="抗锯齿-antialias" tabindex="-1">抗锯齿（Antialias） <a class="header-anchor" href="#抗锯齿-antialias" aria-label="Permalink to &quot;抗锯齿（Antialias）&quot;">​</a></h3><p><img src="'+h+'" alt="jaggies"></p><p><img src="'+p+'" alt="antialiasing"></p><h4 id="锯齿产生的原因" tabindex="-1">锯齿产生的原因 <a class="header-anchor" href="#锯齿产生的原因" aria-label="Permalink to &quot;锯齿产生的原因&quot;">​</a></h4><blockquote><p>个人理解：把图像看成信号，图像信号频率变化太快，但是光栅化采样太慢，形成了空缺，图像不连续，形成了锯齿。</p></blockquote><blockquote><p>一个词解释：undersampling：采样过疏</p></blockquote><h4 id="抗锯齿的方法" tabindex="-1">抗锯齿的方法 <a class="header-anchor" href="#抗锯齿的方法" aria-label="Permalink to &quot;抗锯齿的方法&quot;">​</a></h4><blockquote><p>光栅化采样之前，先对图像边缘进行模糊处理。</p></blockquote><p><img src="'+r+'" alt="blurring"></p><h4 id="抗锯齿原理解析" tabindex="-1">抗锯齿原理解析 <a class="header-anchor" href="#抗锯齿原理解析" aria-label="Permalink to &quot;抗锯齿原理解析&quot;">​</a></h4><ul><li>傅里叶变换</li></ul><p><img src="'+k+'" alt="fourier"></p><ul><li>卷积理论</li></ul><p><img src="'+o+`" alt="convolution"></p><h4 id="实际开发中的抗锯齿" tabindex="-1">实际开发中的抗锯齿 <a class="header-anchor" href="#实际开发中的抗锯齿" aria-label="Permalink to &quot;实际开发中的抗锯齿&quot;">​</a></h4><ul><li>webGL</li></ul><div class="language-js vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">js</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">const</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> context</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> canvas.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">getContext</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;webgl&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, { antialias: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">true</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> });</span></span></code></pre></div><ul><li>THREE.js</li></ul><div class="language-js vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">js</span><pre class="shiki shiki-themes github-light github-dark vp-code"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">const</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> renderer</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> new</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> THREE</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">WebGLRenderer</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">({ antialias: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">true</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> });</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">// or</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">const</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> renderer</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> =</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> new</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> THREE</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">WebGLRenderer</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">();</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">renderer.domElement.style.imageRendering </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;auto&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">renderer.domElement.style.imageRendering </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;crisp-edges&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">;</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">renderer.domElement.style.imageRendering </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &#39;pixelated&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">;</span></span></code></pre></div><h4 id="抗锯齿方法汇总" tabindex="-1">抗锯齿方法汇总 <a class="header-anchor" href="#抗锯齿方法汇总" aria-label="Permalink to &quot;抗锯齿方法汇总&quot;">​</a></h4><ul><li><p>多重采样抗锯齿（Multisample Anti-Aliasing，MSAA）：MSAA 是一种硬件加速的抗锯齿技术。它使用多个采样点来对图像进行抗锯齿处理，每个采样点记录一些像素的颜色和深度信息。通过对这些采样点进行插值，可以减少锯齿状边缘的出现。MSAA 是一种高质量的抗锯齿方法，但它会增加计算开销和内存消耗。</p></li><li><p>快速近似抗锯齿（Fast Approximate Anti-Aliasing，FXAA）：FXAA 是一种基于后处理的抗锯齿技术，它通过对整个图像进行分析和处理来减少锯齿状边缘。FXAA 使用了一些启发式算法和模糊技术，通过对锯齿边缘进行模糊处理来实现抗锯齿效果。FXAA 的优点是速度快，但可能会导致一些图像细节的损失。</p></li><li><p>时域抗锯齿（Temporal Anti-Aliasing，TAA）：TAA 是一种基于时间上的抗锯齿技术，它结合了帧之间的信息来减少锯齿状边缘。TAA 利用了连续帧之间的运动和像素颜色变化的关系，通过对多个帧进行混合和插值来消除锯齿。TAA 可以提供高质量的抗锯齿效果，并且对运动和细节保持较好的处理能力，但它可能会引入一些运动模糊或图像伪影。</p></li></ul><h2 id="深度测试-z-buffer" tabindex="-1">深度测试（Z-buffer） <a class="header-anchor" href="#深度测试-z-buffer" aria-label="Permalink to &quot;深度测试（Z-buffer）&quot;">​</a></h2><h3 id="画家算法" tabindex="-1">画家算法 <a class="header-anchor" href="#画家算法" aria-label="Permalink to &quot;画家算法&quot;">​</a></h3><blockquote><p>基于图形的算法：先画远处的图形，再画近处的图形。</p></blockquote><blockquote><p>三个三角形相互遮挡的情形，无法处理。</p></blockquote><p><img src="`+d+'" alt="triangles"></p><h3 id="z-buffer" tabindex="-1">Z-buffer <a class="header-anchor" href="#z-buffer" aria-label="Permalink to &quot;Z-buffer&quot;">​</a></h3><h4 id="z-buffer-算法过程" tabindex="-1">Z-buffer 算法过程 <a class="header-anchor" href="#z-buffer-算法过程" aria-label="Permalink to &quot;Z-buffer 算法过程&quot;">​</a></h4><ol><li><p>在渲染场景之前，创建一个与屏幕分辨率相同的深度缓冲区（Z-Buffer），用于存储每个像素的深度值。</p></li><li><p>对于每个要渲染的物体，按照其离相机的距离进行排序。通常使用物体的中心点距离相机的距离作为参考。</p></li><li><p>对于每个物体，按照其面片（三角形）的顺序进行渲染。对于每个面片，通过逐像素扫描的方式进行渲染。</p></li><li><p>对于每个像素，计算它在相机空间中的深度值。</p></li><li><p>检查深度缓冲区中该像素的深度值，与当前计算得到的深度值进行比较。</p></li></ol><ul><li><p>如果当前深度值小于深度缓冲区中的值，表示该像素在当前面片前方，更新深度缓冲区的值，并使用当前面片的颜色值来更新屏幕上的像素颜色。</p></li><li><p>如果当前深度值大于或等于深度缓冲区中的值，表示该像素在其他面片前方或处于遮挡状态，不更新深度缓冲区和像素颜色，保留深度缓冲区中的值和之前的颜色。</p></li></ul><ol start="6"><li>重复步骤 4 和步骤 5，直到渲染完所有的物体和面片。</li></ol><h4 id="z-buffer-算法伪代码" tabindex="-1">Z-buffer 算法伪代码 <a class="header-anchor" href="#z-buffer-算法伪代码" aria-label="Permalink to &quot;Z-buffer 算法伪代码&quot;">​</a></h4><p><img src="'+g+'" alt="z-buffer code"></p><h4 id="z-buffer-例子" tabindex="-1">Z-buffer 例子 <a class="header-anchor" href="#z-buffer-例子" aria-label="Permalink to &quot;Z-buffer 例子&quot;">​</a></h4><p><img src="'+c+'" alt="z-buffer example"></p><h2 id="透明物体的深度问题-实际项目中碰到过" tabindex="-1">透明物体的深度问题(实际项目中碰到过) <a class="header-anchor" href="#透明物体的深度问题-实际项目中碰到过" aria-label="Permalink to &quot;透明物体的深度问题(实际项目中碰到过)&quot;">​</a></h2><blockquote><p>在计算机图形学中，处理透明物体的深度排序和渲染是一个复杂的问题。传统的深度缓冲（Z-buffer）算法在处理透明物体时存在一些挑战，因为它们假设物体的渲染顺序是固定的，无法正确处理透明物体的交叠和混合效果。</p></blockquote><blockquote><p>以下是一些常见的方法用于解决透明物体深度排序的问题：</p></blockquote><ul><li><p>前向渲染（Forward Rendering）：在前向渲染中，透明物体按照离相机的距离进行排序，并按照顺序渲染到屏幕上。这样可以确保前面的透明物体覆盖后面的物体。然而，前向渲染需要对每个透明物体进行排序，增加了渲染的复杂性和计算开销。</p></li><li><p>深度排序算法（Depth Sorting Algorithms）：深度排序算法用于对透明物体进行排序，以便按正确的顺序渲染它们。常见的深度排序算法包括离相机距离排序、图元重排序（如 BSP 树、八叉树等）、Alpha 混合排序等。这些算法可以根据透明物体之间的相互遮挡关系和混合模式进行排序。</p></li><li><p>延迟混合（Deferred Blending）：延迟混合是一种用于处理透明物体的深度问题的技术。它通过将透明物体的颜色和深度信息存储在附加的缓冲区中，并在最后阶段进行混合操作。这样可以解决透明物体的深度排序问题，并且可以在片段着色器中使用透明度（Alpha）值进行混合计算。</p></li><li><p>顺序无关透明度（Order-Independent Transparency，OIT）：OIT 是一种使用多种技术来处理透明物体的深度问题的方法。它包括基于排序的方法、多层深度缓冲（如 Dual Depth Peeling）和基于像素的排序等。OIT 技术可以实现更高质量的透明效果，但通常需要更多的计算和内存开销。</p></li></ul>',51),m=[E];function y(b,f,F,A,q,_){return a(),s("div",null,m)}const D=i(u,[["render",y]]);export{x as __pageData,D as default};
